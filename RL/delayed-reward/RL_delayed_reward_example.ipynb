{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0Cx2S26ku9amEXjeruu0D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamclark/jupyter-notebooks/blob/main/RL/delayed-reward/RL_delayed_reward_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3 -q"
      ],
      "metadata": {
        "id": "n34iDm-AHbPk",
        "outputId": "fad4ee98-b6ce-4ae7-9f71-d5f370b79633",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import BaseCallback"
      ],
      "metadata": {
        "id": "eMIJ0Am8Hftz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ› ï¸ Custom environment with only terminal reward\n",
        "class TerminalRewardEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(TerminalRewardEnv, self).__init__()\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(4,), dtype=np.float32)\n",
        "        self.action_space = spaces.Discrete(2)\n",
        "        self.current_step = 0\n",
        "        self.max_steps = 20\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = 0\n",
        "        return self._get_obs(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "        truncated = False  # Use True if episode truncated by timeout or external reason\n",
        "\n",
        "        reward = 0.0\n",
        "        if done:\n",
        "            # Reward is only given at the end of the episode\n",
        "            reward = np.random.choice([1.0, 0.0], p=[0.3, 0.7])  # Random success\n",
        "        return self._get_obs(), reward, done, truncated, {}\n",
        "\n",
        "    def _get_obs(self):\n",
        "        return np.random.rand(4).astype(np.float32)\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        print(f\"Step: {self.current_step}, State: {self.state}\")\n",
        "\n",
        "# ðŸ“‹ Callback to print final reward of each episode\n",
        "class TerminalRewardLogger(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "        self.episode_rewards = []\n",
        "        self.episode_step_count = 0\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        self.episode_step_count += 1\n",
        "        done = self.locals[\"dones\"][0]\n",
        "        reward = self.locals[\"rewards\"][0]\n",
        "        if done:\n",
        "            self.episode_rewards.append(reward)\n",
        "            print(f\"Episode {len(self.episode_rewards)} took {self.episode_step_count} steps and ended with reward: {reward}\")\n",
        "            self.episode_step_count = 0\n",
        "        return True"
      ],
      "metadata": {
        "id": "nOmKd-nsHDTm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-vL56qHG_lS",
        "outputId": "e872be49-027c-4522-cf0e-d3e9d573564d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1 took 20 steps and ended with reward: 1.0\n",
            "Episode 2 took 20 steps and ended with reward: 0.0\n",
            "Episode 3 took 20 steps and ended with reward: 0.0\n",
            "Episode 4 took 20 steps and ended with reward: 0.0\n",
            "Episode 5 took 20 steps and ended with reward: 1.0\n",
            "Episode 6 took 20 steps and ended with reward: 0.0\n",
            "Episode 7 took 20 steps and ended with reward: 1.0\n",
            "Episode 8 took 20 steps and ended with reward: 0.0\n",
            "Episode 9 took 20 steps and ended with reward: 0.0\n",
            "Episode 10 took 20 steps and ended with reward: 0.0\n",
            "Episode 11 took 20 steps and ended with reward: 0.0\n",
            "Episode 12 took 20 steps and ended with reward: 0.0\n",
            "Episode 13 took 20 steps and ended with reward: 0.0\n",
            "Episode 14 took 20 steps and ended with reward: 1.0\n",
            "Episode 15 took 20 steps and ended with reward: 0.0\n",
            "Episode 16 took 20 steps and ended with reward: 0.0\n",
            "Episode 17 took 20 steps and ended with reward: 1.0\n",
            "Episode 18 took 20 steps and ended with reward: 0.0\n",
            "Episode 19 took 20 steps and ended with reward: 0.0\n",
            "Episode 20 took 20 steps and ended with reward: 0.0\n",
            "Episode 21 took 20 steps and ended with reward: 0.0\n",
            "Episode 22 took 20 steps and ended with reward: 1.0\n",
            "Episode 23 took 20 steps and ended with reward: 1.0\n",
            "Episode 24 took 20 steps and ended with reward: 1.0\n",
            "Episode 25 took 20 steps and ended with reward: 0.0\n",
            "Episode 26 took 20 steps and ended with reward: 0.0\n",
            "Episode 27 took 20 steps and ended with reward: 0.0\n",
            "Episode 28 took 20 steps and ended with reward: 0.0\n",
            "Episode 29 took 20 steps and ended with reward: 0.0\n",
            "Episode 30 took 20 steps and ended with reward: 0.0\n",
            "Episode 31 took 20 steps and ended with reward: 0.0\n",
            "Episode 32 took 20 steps and ended with reward: 1.0\n",
            "Episode 33 took 20 steps and ended with reward: 0.0\n",
            "Episode 34 took 20 steps and ended with reward: 0.0\n",
            "Episode 35 took 20 steps and ended with reward: 0.0\n",
            "Episode 36 took 20 steps and ended with reward: 0.0\n",
            "Episode 37 took 20 steps and ended with reward: 0.0\n",
            "Episode 38 took 20 steps and ended with reward: 1.0\n",
            "Episode 39 took 20 steps and ended with reward: 1.0\n",
            "Episode 40 took 20 steps and ended with reward: 0.0\n",
            "Episode 41 took 20 steps and ended with reward: 0.0\n",
            "Episode 42 took 20 steps and ended with reward: 0.0\n",
            "Episode 43 took 20 steps and ended with reward: 0.0\n",
            "Episode 44 took 20 steps and ended with reward: 0.0\n",
            "Episode 45 took 20 steps and ended with reward: 0.0\n",
            "Episode 46 took 20 steps and ended with reward: 1.0\n",
            "Episode 47 took 20 steps and ended with reward: 1.0\n",
            "Episode 48 took 20 steps and ended with reward: 0.0\n",
            "Episode 49 took 20 steps and ended with reward: 1.0\n",
            "Episode 50 took 20 steps and ended with reward: 1.0\n",
            "Episode 51 took 20 steps and ended with reward: 0.0\n",
            "Episode 52 took 20 steps and ended with reward: 0.0\n",
            "Episode 53 took 20 steps and ended with reward: 0.0\n",
            "Episode 54 took 20 steps and ended with reward: 0.0\n",
            "Episode 55 took 20 steps and ended with reward: 1.0\n",
            "Episode 56 took 20 steps and ended with reward: 0.0\n",
            "Episode 57 took 20 steps and ended with reward: 0.0\n",
            "Episode 58 took 20 steps and ended with reward: 1.0\n",
            "Episode 59 took 20 steps and ended with reward: 0.0\n",
            "Episode 60 took 20 steps and ended with reward: 0.0\n",
            "Episode 61 took 20 steps and ended with reward: 0.0\n",
            "Episode 62 took 20 steps and ended with reward: 1.0\n",
            "Episode 63 took 20 steps and ended with reward: 0.0\n",
            "Episode 64 took 20 steps and ended with reward: 0.0\n",
            "Episode 65 took 20 steps and ended with reward: 0.0\n",
            "Episode 66 took 20 steps and ended with reward: 0.0\n",
            "Episode 67 took 20 steps and ended with reward: 0.0\n",
            "Episode 68 took 20 steps and ended with reward: 0.0\n",
            "Episode 69 took 20 steps and ended with reward: 0.0\n",
            "Episode 70 took 20 steps and ended with reward: 1.0\n",
            "Episode 71 took 20 steps and ended with reward: 0.0\n",
            "Episode 72 took 20 steps and ended with reward: 0.0\n",
            "Episode 73 took 20 steps and ended with reward: 1.0\n",
            "Episode 74 took 20 steps and ended with reward: 0.0\n",
            "Episode 75 took 20 steps and ended with reward: 1.0\n",
            "Episode 76 took 20 steps and ended with reward: 1.0\n",
            "Episode 77 took 20 steps and ended with reward: 1.0\n",
            "Episode 78 took 20 steps and ended with reward: 0.0\n",
            "Episode 79 took 20 steps and ended with reward: 1.0\n",
            "Episode 80 took 20 steps and ended with reward: 1.0\n",
            "Episode 81 took 20 steps and ended with reward: 0.0\n",
            "Episode 82 took 20 steps and ended with reward: 0.0\n",
            "Episode 83 took 20 steps and ended with reward: 0.0\n",
            "Episode 84 took 20 steps and ended with reward: 1.0\n",
            "Episode 85 took 20 steps and ended with reward: 1.0\n",
            "Episode 86 took 20 steps and ended with reward: 0.0\n",
            "Episode 87 took 20 steps and ended with reward: 0.0\n",
            "Episode 88 took 20 steps and ended with reward: 0.0\n",
            "Episode 89 took 20 steps and ended with reward: 1.0\n",
            "Episode 90 took 20 steps and ended with reward: 1.0\n",
            "Episode 91 took 20 steps and ended with reward: 0.0\n",
            "Episode 92 took 20 steps and ended with reward: 0.0\n",
            "Episode 93 took 20 steps and ended with reward: 1.0\n",
            "Episode 94 took 20 steps and ended with reward: 1.0\n",
            "Episode 95 took 20 steps and ended with reward: 0.0\n",
            "Episode 96 took 20 steps and ended with reward: 0.0\n",
            "Episode 97 took 20 steps and ended with reward: 0.0\n",
            "Episode 98 took 20 steps and ended with reward: 0.0\n",
            "Episode 99 took 20 steps and ended with reward: 1.0\n",
            "Episode 100 took 20 steps and ended with reward: 1.0\n",
            "Episode 101 took 20 steps and ended with reward: 0.0\n",
            "Episode 102 took 20 steps and ended with reward: 0.0\n",
            "Episode 103 took 20 steps and ended with reward: 0.0\n",
            "Episode 104 took 20 steps and ended with reward: 1.0\n",
            "Episode 105 took 20 steps and ended with reward: 1.0\n",
            "Episode 106 took 20 steps and ended with reward: 0.0\n",
            "Episode 107 took 20 steps and ended with reward: 0.0\n",
            "Episode 108 took 20 steps and ended with reward: 0.0\n",
            "Episode 109 took 20 steps and ended with reward: 1.0\n",
            "Episode 110 took 20 steps and ended with reward: 0.0\n",
            "Episode 111 took 20 steps and ended with reward: 0.0\n",
            "Episode 112 took 20 steps and ended with reward: 1.0\n",
            "Episode 113 took 20 steps and ended with reward: 0.0\n",
            "Episode 114 took 20 steps and ended with reward: 1.0\n",
            "Episode 115 took 20 steps and ended with reward: 1.0\n",
            "Episode 116 took 20 steps and ended with reward: 0.0\n",
            "Episode 117 took 20 steps and ended with reward: 0.0\n",
            "Episode 118 took 20 steps and ended with reward: 0.0\n",
            "Episode 119 took 20 steps and ended with reward: 0.0\n",
            "Episode 120 took 20 steps and ended with reward: 0.0\n",
            "Episode 121 took 20 steps and ended with reward: 0.0\n",
            "Episode 122 took 20 steps and ended with reward: 0.0\n",
            "Episode 123 took 20 steps and ended with reward: 0.0\n",
            "Episode 124 took 20 steps and ended with reward: 0.0\n",
            "Episode 125 took 20 steps and ended with reward: 0.0\n",
            "Episode 126 took 20 steps and ended with reward: 0.0\n",
            "Episode 127 took 20 steps and ended with reward: 0.0\n",
            "Episode 128 took 20 steps and ended with reward: 0.0\n",
            "Episode 129 took 20 steps and ended with reward: 0.0\n",
            "Episode 130 took 20 steps and ended with reward: 0.0\n",
            "Episode 131 took 20 steps and ended with reward: 0.0\n",
            "Episode 132 took 20 steps and ended with reward: 0.0\n",
            "Episode 133 took 20 steps and ended with reward: 0.0\n",
            "Episode 134 took 20 steps and ended with reward: 0.0\n",
            "Episode 135 took 20 steps and ended with reward: 0.0\n",
            "Episode 136 took 20 steps and ended with reward: 0.0\n",
            "Episode 137 took 20 steps and ended with reward: 0.0\n",
            "Episode 138 took 20 steps and ended with reward: 0.0\n",
            "Episode 139 took 20 steps and ended with reward: 1.0\n",
            "Episode 140 took 20 steps and ended with reward: 0.0\n",
            "Episode 141 took 20 steps and ended with reward: 1.0\n",
            "Episode 142 took 20 steps and ended with reward: 0.0\n",
            "Episode 143 took 20 steps and ended with reward: 0.0\n",
            "Episode 144 took 20 steps and ended with reward: 1.0\n",
            "Episode 145 took 20 steps and ended with reward: 1.0\n",
            "Episode 146 took 20 steps and ended with reward: 1.0\n",
            "Episode 147 took 20 steps and ended with reward: 1.0\n",
            "Episode 148 took 20 steps and ended with reward: 1.0\n",
            "Episode 149 took 20 steps and ended with reward: 0.0\n",
            "Episode 150 took 20 steps and ended with reward: 0.0\n",
            "Episode 151 took 20 steps and ended with reward: 1.0\n",
            "Episode 152 took 20 steps and ended with reward: 1.0\n",
            "Episode 153 took 20 steps and ended with reward: 0.0\n",
            "Episode 154 took 20 steps and ended with reward: 0.0\n",
            "Episode 155 took 20 steps and ended with reward: 0.0\n",
            "Episode 156 took 20 steps and ended with reward: 1.0\n",
            "Episode 157 took 20 steps and ended with reward: 0.0\n",
            "Episode 158 took 20 steps and ended with reward: 0.0\n",
            "Episode 159 took 20 steps and ended with reward: 0.0\n",
            "Episode 160 took 20 steps and ended with reward: 1.0\n",
            "Episode 161 took 20 steps and ended with reward: 0.0\n",
            "Episode 162 took 20 steps and ended with reward: 0.0\n",
            "Episode 163 took 20 steps and ended with reward: 0.0\n",
            "Episode 164 took 20 steps and ended with reward: 0.0\n",
            "Episode 165 took 20 steps and ended with reward: 0.0\n",
            "Episode 166 took 20 steps and ended with reward: 0.0\n",
            "Episode 167 took 20 steps and ended with reward: 0.0\n",
            "Episode 168 took 20 steps and ended with reward: 1.0\n",
            "Episode 169 took 20 steps and ended with reward: 0.0\n",
            "Episode 170 took 20 steps and ended with reward: 0.0\n",
            "Episode 171 took 20 steps and ended with reward: 1.0\n",
            "Episode 172 took 20 steps and ended with reward: 1.0\n",
            "Episode 173 took 20 steps and ended with reward: 0.0\n",
            "Episode 174 took 20 steps and ended with reward: 1.0\n",
            "Episode 175 took 20 steps and ended with reward: 0.0\n",
            "Episode 176 took 20 steps and ended with reward: 0.0\n",
            "Episode 177 took 20 steps and ended with reward: 0.0\n",
            "Episode 178 took 20 steps and ended with reward: 0.0\n",
            "Episode 179 took 20 steps and ended with reward: 1.0\n",
            "Episode 180 took 20 steps and ended with reward: 1.0\n",
            "Episode 181 took 20 steps and ended with reward: 0.0\n",
            "Episode 182 took 20 steps and ended with reward: 0.0\n",
            "Episode 183 took 20 steps and ended with reward: 1.0\n",
            "Episode 184 took 20 steps and ended with reward: 1.0\n",
            "Episode 185 took 20 steps and ended with reward: 0.0\n",
            "Episode 186 took 20 steps and ended with reward: 1.0\n",
            "Episode 187 took 20 steps and ended with reward: 1.0\n",
            "Episode 188 took 20 steps and ended with reward: 0.0\n",
            "Episode 189 took 20 steps and ended with reward: 0.0\n",
            "Episode 190 took 20 steps and ended with reward: 1.0\n",
            "Episode 191 took 20 steps and ended with reward: 0.0\n",
            "Episode 192 took 20 steps and ended with reward: 0.0\n",
            "Episode 193 took 20 steps and ended with reward: 0.0\n",
            "Episode 194 took 20 steps and ended with reward: 0.0\n",
            "Episode 195 took 20 steps and ended with reward: 0.0\n",
            "Episode 196 took 20 steps and ended with reward: 0.0\n",
            "Episode 197 took 20 steps and ended with reward: 0.0\n",
            "Episode 198 took 20 steps and ended with reward: 0.0\n",
            "Episode 199 took 20 steps and ended with reward: 0.0\n",
            "Episode 200 took 20 steps and ended with reward: 1.0\n",
            "Episode 201 took 20 steps and ended with reward: 0.0\n",
            "Episode 202 took 20 steps and ended with reward: 0.0\n",
            "Episode 203 took 20 steps and ended with reward: 0.0\n",
            "Episode 204 took 20 steps and ended with reward: 0.0\n",
            "Episode 205 took 20 steps and ended with reward: 1.0\n",
            "Episode 206 took 20 steps and ended with reward: 0.0\n",
            "Episode 207 took 20 steps and ended with reward: 0.0\n",
            "Episode 208 took 20 steps and ended with reward: 0.0\n",
            "Episode 209 took 20 steps and ended with reward: 1.0\n",
            "Episode 210 took 20 steps and ended with reward: 0.0\n",
            "Episode 211 took 20 steps and ended with reward: 0.0\n",
            "Episode 212 took 20 steps and ended with reward: 1.0\n",
            "Episode 213 took 20 steps and ended with reward: 1.0\n",
            "Episode 214 took 20 steps and ended with reward: 0.0\n",
            "Episode 215 took 20 steps and ended with reward: 0.0\n",
            "Episode 216 took 20 steps and ended with reward: 1.0\n",
            "Episode 217 took 20 steps and ended with reward: 1.0\n",
            "Episode 218 took 20 steps and ended with reward: 1.0\n",
            "Episode 219 took 20 steps and ended with reward: 0.0\n",
            "Episode 220 took 20 steps and ended with reward: 1.0\n",
            "Episode 221 took 20 steps and ended with reward: 1.0\n",
            "Episode 222 took 20 steps and ended with reward: 1.0\n",
            "Episode 223 took 20 steps and ended with reward: 0.0\n",
            "Episode 224 took 20 steps and ended with reward: 0.0\n",
            "Episode 225 took 20 steps and ended with reward: 0.0\n",
            "Episode 226 took 20 steps and ended with reward: 1.0\n",
            "Episode 227 took 20 steps and ended with reward: 0.0\n",
            "Episode 228 took 20 steps and ended with reward: 0.0\n",
            "Episode 229 took 20 steps and ended with reward: 0.0\n",
            "Episode 230 took 20 steps and ended with reward: 0.0\n",
            "Episode 231 took 20 steps and ended with reward: 0.0\n",
            "Episode 232 took 20 steps and ended with reward: 0.0\n",
            "Episode 233 took 20 steps and ended with reward: 0.0\n",
            "Episode 234 took 20 steps and ended with reward: 1.0\n",
            "Episode 235 took 20 steps and ended with reward: 0.0\n",
            "Episode 236 took 20 steps and ended with reward: 0.0\n",
            "Episode 237 took 20 steps and ended with reward: 1.0\n",
            "Episode 238 took 20 steps and ended with reward: 0.0\n",
            "Episode 239 took 20 steps and ended with reward: 0.0\n",
            "Episode 240 took 20 steps and ended with reward: 0.0\n",
            "Episode 241 took 20 steps and ended with reward: 1.0\n",
            "Episode 242 took 20 steps and ended with reward: 0.0\n",
            "Episode 243 took 20 steps and ended with reward: 0.0\n",
            "Episode 244 took 20 steps and ended with reward: 1.0\n",
            "Episode 245 took 20 steps and ended with reward: 1.0\n",
            "Episode 246 took 20 steps and ended with reward: 1.0\n",
            "Episode 247 took 20 steps and ended with reward: 1.0\n",
            "Episode 248 took 20 steps and ended with reward: 1.0\n",
            "Episode 249 took 20 steps and ended with reward: 0.0\n",
            "Episode 250 took 20 steps and ended with reward: 1.0\n",
            "Episode 251 took 20 steps and ended with reward: 1.0\n",
            "Episode 252 took 20 steps and ended with reward: 1.0\n",
            "Episode 253 took 20 steps and ended with reward: 0.0\n",
            "Episode 254 took 20 steps and ended with reward: 0.0\n",
            "Episode 255 took 20 steps and ended with reward: 0.0\n",
            "Episode 256 took 20 steps and ended with reward: 0.0\n",
            "Episode 257 took 20 steps and ended with reward: 0.0\n",
            "Episode 258 took 20 steps and ended with reward: 0.0\n",
            "Episode 259 took 20 steps and ended with reward: 1.0\n",
            "Episode 260 took 20 steps and ended with reward: 0.0\n",
            "Episode 261 took 20 steps and ended with reward: 1.0\n",
            "Episode 262 took 20 steps and ended with reward: 1.0\n",
            "Episode 263 took 20 steps and ended with reward: 0.0\n",
            "Episode 264 took 20 steps and ended with reward: 1.0\n",
            "Episode 265 took 20 steps and ended with reward: 0.0\n",
            "Episode 266 took 20 steps and ended with reward: 0.0\n",
            "Episode 267 took 20 steps and ended with reward: 0.0\n",
            "Episode 268 took 20 steps and ended with reward: 0.0\n",
            "Episode 269 took 20 steps and ended with reward: 0.0\n",
            "Episode 270 took 20 steps and ended with reward: 0.0\n",
            "Episode 271 took 20 steps and ended with reward: 1.0\n",
            "Episode 272 took 20 steps and ended with reward: 1.0\n",
            "Episode 273 took 20 steps and ended with reward: 0.0\n",
            "Episode 274 took 20 steps and ended with reward: 0.0\n",
            "Episode 275 took 20 steps and ended with reward: 0.0\n",
            "Episode 276 took 20 steps and ended with reward: 0.0\n",
            "Episode 277 took 20 steps and ended with reward: 0.0\n",
            "Episode 278 took 20 steps and ended with reward: 0.0\n",
            "Episode 279 took 20 steps and ended with reward: 1.0\n",
            "Episode 280 took 20 steps and ended with reward: 1.0\n",
            "Episode 281 took 20 steps and ended with reward: 0.0\n",
            "Episode 282 took 20 steps and ended with reward: 0.0\n",
            "Episode 283 took 20 steps and ended with reward: 1.0\n",
            "Episode 284 took 20 steps and ended with reward: 1.0\n",
            "Episode 285 took 20 steps and ended with reward: 0.0\n",
            "Episode 286 took 20 steps and ended with reward: 0.0\n",
            "Episode 287 took 20 steps and ended with reward: 0.0\n",
            "Episode 288 took 20 steps and ended with reward: 0.0\n",
            "Episode 289 took 20 steps and ended with reward: 1.0\n",
            "Episode 290 took 20 steps and ended with reward: 0.0\n",
            "Episode 291 took 20 steps and ended with reward: 0.0\n",
            "Episode 292 took 20 steps and ended with reward: 0.0\n",
            "Episode 293 took 20 steps and ended with reward: 0.0\n",
            "Episode 294 took 20 steps and ended with reward: 1.0\n",
            "Episode 295 took 20 steps and ended with reward: 0.0\n",
            "Episode 296 took 20 steps and ended with reward: 0.0\n",
            "Episode 297 took 20 steps and ended with reward: 0.0\n",
            "Episode 298 took 20 steps and ended with reward: 0.0\n",
            "Episode 299 took 20 steps and ended with reward: 0.0\n",
            "Episode 300 took 20 steps and ended with reward: 1.0\n",
            "Episode 301 took 20 steps and ended with reward: 0.0\n",
            "Episode 302 took 20 steps and ended with reward: 0.0\n",
            "Episode 303 took 20 steps and ended with reward: 1.0\n",
            "Episode 304 took 20 steps and ended with reward: 0.0\n",
            "Episode 305 took 20 steps and ended with reward: 0.0\n",
            "Episode 306 took 20 steps and ended with reward: 1.0\n",
            "Episode 307 took 20 steps and ended with reward: 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x79a9984fb950>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# ðŸŽ® Instantiate env and model\n",
        "env = TerminalRewardEnv()\n",
        "model = PPO(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# ðŸš€ Train with reward logger\n",
        "logger = TerminalRewardLogger()\n",
        "model.learn(total_timesteps=5000, callback=logger)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs, info = env.reset()  # Reset environment and get initial observation\n",
        "\n",
        "for _ in range(20):  # Run for 20 steps (or full episode length)\n",
        "    action, _states = model.predict(obs, deterministic=True)  # Predict action given observation\n",
        "    obs, reward, done, truncated, info = env.step(action)  # Take action in environment\n",
        "    env.render()  # (Optional) render the environment if supported\n",
        "\n",
        "    if done:\n",
        "        print(\"Episode finished\")\n",
        "        break"
      ],
      "metadata": {
        "id": "szab5iljQh2i",
        "outputId": "c086bc76-995c-4aa6-ad58-255f46dc0c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'TerminalRewardEnv' object has no attribute 'state'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6ed0ae6761e0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Predict action given observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Take action in environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (Optional) render the environment if supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-2f83dc5de077>\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Step: {self.current_step}, State: {self.state}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# ðŸ“‹ Callback to print final reward of each episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TerminalRewardEnv' object has no attribute 'state'"
          ]
        }
      ]
    }
  ]
}